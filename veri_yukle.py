import numpy as np
import pandas as pd

# Rastgelelik iÃ§in sabit bir tohum deÄŸeri belirleyelim
np.random.seed(42)

# Mevcut veri seti
data = {
    "YaÅŸ": np.random.randint(18, 90, 1000),
    "Cinsiyet": np.random.choice(["KadÄ±n", "Erkek"], 1000),
    "BMI": np.round(np.random.uniform(18.5, 40, 1000), 2),
    "NabÄ±z": np.random.randint(60, 120, 1000),
    "Tansiyon_Sistolik": np.random.randint(90, 180, 1000),
    "Tansiyon_Diastolik": np.random.randint(60, 120, 1000),
    "Oksijen_DoygunluÄŸu": np.random.randint(85, 100, 1000),
    "Kalp_Hastaligi": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "Kanser": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "Tansiyon_Problemi": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "Kolesterol_Sorunu": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "Panik_Atak": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "Son_Ameliyat": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "Kirik": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "Cikik": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "Kalp_Krizi": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "Ic_Kanama": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "Kesik": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "Yaralanma": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "Beyin_Kanamasi": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "Uzuv_Kopmasi": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "Sikisma": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "Omurilik_Zedelenmesi": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "AÄŸrÄ±_Seviyesi": np.random.randint(1, 11, 1000),
    "Stres_Seviyesi": np.random.randint(1, 11, 1000),
    "Tedaviye_UlaÅŸma_SÃ¼resi": np.random.randint(5, 60, 1000),
    "SaÄŸlÄ±k_Ekibi_Kapasitesi": np.random.randint(1, 6, 1000),
    "AteÅŸ": np.round(np.random.uniform(36.0, 41.0, 1000), 1),
    "BulantÄ±": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "Kusma": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "BayÄ±lma": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "BilinÃ§_Durumu": np.random.choice(["Normal", "Sersem", "BilinÃ§siz"], 1000),
    "Epilepsi": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "KOAH": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "BÃ¶brek_YetmezliÄŸi": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "YanÄ±k": np.random.choice(["1. Derece", "2. Derece", "3. Derece", "Yok"], 1000),
    "Zehirlenme": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "BoÄŸulma": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "Åiddetli_BaÅŸ_AÄŸrÄ±sÄ±": np.random.randint(1, 11, 1000),
    "Laboratuvar_SonuÃ§larÄ±": np.random.randint(50, 200, 1000),
    "Kan_Åekeri": np.random.randint(70, 200, 1000),
    "Kalp_HÄ±zÄ±_DeÄŸiÅŸkenliÄŸi": np.round(np.random.uniform(10, 150, 1000), 2),
    "Nefes_DarlÄ±ÄŸÄ±": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "HastanÄ±n_Medikal_GeÃ§miÅŸi": np.random.choice(
    ["Kalp", "BÃ¶brek", "AkciÄŸer", "Normal", "Kanser", "KOAH", "Diabetes", "Hipertansiyon", "NÃ¶rolojik"],
    1000),
    "Åok_Belirtileri": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "GÃ¶z_BebeÄŸi_Tepkisi": np.random.choice(["Normal", "YavaÅŸ", "Tepkisiz"], 1000),
    "Ä°shal": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "AÄŸrÄ±_Konumu": np.random.choice(["BaÅŸ", "KarÄ±n", "GÃ¶ÄŸÃ¼s", "SÄ±rt", "Bacak", "Kol"], 1000),
    "GÃ¶ÄŸÃ¼s_AÄŸrÄ±sÄ±": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "VÃ¼cut_SÄ±caklÄ±ÄŸÄ±_DeÄŸiÅŸkenliÄŸi": np.round(np.random.uniform(35.0, 42.0, 1000), 1),
    "Susuzluk_Belirtileri": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "Son_24_Saatte_Yemek_Yedi": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "Cilt_KuruluÄŸu": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "NÃ¶rolojik_Belirtiler": np.random.choice(["Normal", "KonuÅŸma BozukluÄŸu", "UyuÅŸukluk"], 1000),
    "Hasta_KaÃ§_Saat_Ã–nce_YaralandÄ±": np.random.randint(0, 24, 1000),
    "Olay_TÃ¼rÃ¼": np.random.choice(["Trafik KazasÄ±", "Ev KazasÄ±", "Spor YaralanmasÄ±", "Sanayi KazasÄ±", "Olay Yok"], 1000),
    "Ä°lk_MÃ¼dahale_YapÄ±ldÄ±": np.random.choice(["Evet", "HayÄ±r"], 1000),
    "HastanÄ±n_Ã–nceki_Hastane_Ziyaretleri": np.random.randint(0, 11, 1000),
    "Acil_Servise_GeldiÄŸi_Saat": np.random.randint(0, 24, 1000),
}
# Veri Ã§erÃ§evesi oluÅŸturma
df = pd.DataFrame(data)

# GÃ¼ncellenmiÅŸ veri Ã§erÃ§evesini oluÅŸturalÄ±m
df_final = pd.DataFrame(data)

# CSV olarak kaydedelim
df_final.to_csv("guncellenmis_veri_seti.csv", index=False)

import pandas as pd

# CSV dosyanÄ±n adÄ±nÄ± doÄŸru gir
dosya_yolu = "guncellenmis_veri_seti.csv"

# Veri setini yÃ¼kle
df = pd.read_csv(dosya_yolu)

# Ä°lk birkaÃ§ satÄ±rÄ± gÃ¶rÃ¼ntÃ¼le
print("ğŸ“Œ Veri Setinin Ä°lk SatÄ±rlarÄ±:")
print(df.head())

# SÃ¼tun isimlerini gÃ¶rÃ¼ntÃ¼le
print("\nğŸ“Œ SÃ¼tun Ä°simleri:")
print(df.columns)

# Veri tÃ¼rlerini incele
print("\nğŸ“Œ Veri TÃ¼rleri:")
print(df.dtypes)

# Eksik deÄŸerleri kontrol et
print("\nğŸ“Œ Eksik Veri SayÄ±sÄ±:")
print(df.isnull().sum())

# Temel istatistiksel Ã¶zet
print("\nğŸ“Œ Genel Ä°statistiksel Ã–zet:")
print(df.describe(include="all"))

import pandas as pd

# CSV dosyanÄ±n adÄ±nÄ± doÄŸru gir
dosya_yolu = "guncellenmis_veri_seti.csv"

# Veri setini tekrar yÃ¼kle
df = pd.read_csv(dosya_yolu)

# "Evet" â†’ 1, "HayÄ±r" â†’ 0 dÃ¶nÃ¼ÅŸÃ¼mÃ¼
evet_hayir_sutunlari = ["Kalp_Hastaligi", "Kanser", "Tansiyon_Problemi", "Kolesterol_Sorunu",
                         "Panik_Atak", "Son_Ameliyat", "Kirik", "Cikik", "Kalp_Krizi",
                         "Ic_Kanama", "Kesik", "Yaralanma", "Beyin_Kanamasi", "Uzuv_Kopmasi",
                         "Sikisma", "Omurilik_Zedelenmesi", "BulantÄ±", "Kusma", "BayÄ±lma",
                         "Epilepsi", "KOAH", "BÃ¶brek_YetmezliÄŸi", "Zehirlenme", "BoÄŸulma",
                         "Nefes_DarlÄ±ÄŸÄ±", "Åok_Belirtileri", "Ä°shal", "GÃ¶ÄŸÃ¼s_AÄŸrÄ±sÄ±",
                         "Susuzluk_Belirtileri", "Son_24_Saatte_Yemek_Yedi", "Cilt_KuruluÄŸu",
                         "Ä°lk_MÃ¼dahale_YapÄ±ldÄ±"]

for col in evet_hayir_sutunlari:
    df[col] = df[col].map({"Evet": 1, "HayÄ±r": 0})

# "KadÄ±n" â†’ 0, "Erkek" â†’ 1 dÃ¶nÃ¼ÅŸÃ¼mÃ¼
df["Cinsiyet"] = df["Cinsiyet"].map({"KadÄ±n": 0, "Erkek": 1})

# "Normal", "Sersem", "BilinÃ§siz" gibi kategorik sÃ¼tunlarÄ± sayÄ±sal hale getirme
kategorik_sutunlar = ["BilinÃ§_Durumu", "YanÄ±k", "Olay_TÃ¼rÃ¼", "GÃ¶z_BebeÄŸi_Tepkisi", "NÃ¶rolojik_Belirtiler"]

df = pd.get_dummies(df, columns=kategorik_sutunlar)

# DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ veri setini kaydet
df.to_csv("temizlenmis_veri_seti.csv", index=False)

# Ä°ÅŸlem tamamlandÄ± mesajÄ±
print("âœ… Kategorik veriler baÅŸarÄ±yla sayÄ±sal hale getirildi ve temizlenmiÅŸ veri kaydedildi!")

import pandas as pd

# TemizlenmiÅŸ veri setini tekrar yÃ¼kle
df = pd.read_csv("temizlenmis_veri_seti.csv")

# Veri setinin ilk birkaÃ§ satÄ±rÄ±na bakalÄ±m
print("ğŸ“Œ TemizlenmiÅŸ Veri Setinin Ä°lk SatÄ±rlarÄ±:")
print(df.head())

# Veri tÃ¼rlerini inceleyelim
print("\nğŸ“Œ Veri TÃ¼rleri:")
print(df.dtypes)

# Eksik veri var mÄ± kontrol edelim
print("\nğŸ“Œ Eksik Veri SayÄ±sÄ±:")
print(df.isnull().sum())

# Genel istatistiksel Ã¶zet
print("\nğŸ“Œ Genel Ä°statistiksel Ã–zet:")
print(df.describe(include="all"))

import pandas as pd

# TemizlenmiÅŸ veri setini yÃ¼kle
df = pd.read_csv("temizlenmis_veri_seti.csv")

# Mevcut sÃ¼tun isimlerini yazdÄ±r
print("ğŸ“Œ Mevcut SÃ¼tun Ä°simleri:")
print(df.columns)

import pandas as pd

# TemizlenmiÅŸ veri setini yÃ¼kle
df = pd.read_csv("temizlenmis_veri_seti.csv")


# Aciliyet seviyesi hesaplama fonksiyonu
def hesapla_aciliyet(row):
    # Hayati tehlike oluÅŸturan hastalÄ±klar
    hayati_tehlike = ["Kalp_Krizi", "Ic_Kanama", "Beyin_Kanamasi", "Uzuv_Kopmasi"]

    # EÄŸer hayati tehlike varsa, doÄŸrudan YÃœKSEK RÄ°SK (2)
    if any(row[col] == 1 for col in hayati_tehlike):
        return 2

    # EÄŸer bilinÃ§sizse veya oksijen seviyesi Ã§ok dÃ¼ÅŸÃ¼kse, YÃœKSEK RÄ°SK (2)
    if row["BilinÃ§_Durumu_BilinÃ§siz"] == 1 or row["Oksijen_DoygunluÄŸu"] < 90:
        return 2

    # EÄŸer aÄŸrÄ± seviyesi 8 ve Ã¼stÃ¼yse ve stres seviyesi 7+ ise, ORTA RÄ°SK (1)
    if row["AÄŸrÄ±_Seviyesi"] >= 8 and row["Stres_Seviyesi"] >= 7:
        return 1

    # EÄŸer tansiyon Ã§ok dÃ¼ÅŸÃ¼k veya Ã§ok yÃ¼ksekse, ORTA RÄ°SK (1)
    if row["Tansiyon_Sistolik"] < 100 or row["Tansiyon_Sistolik"] > 160:
        return 1

    # EÄŸer herhangi bir kriter saÄŸlanmadÄ±ysa, DÃœÅÃœK RÄ°SK (0)
    return 0


# Aciliyet seviyesini hesaplayÄ±p ekleyelim
df["Aciliyet_Seviyesi"] = df.apply(hesapla_aciliyet, axis=1)

# Yeni veri setini kaydet
df.to_csv("aciliyetli_veri_seti.csv", index=False)

print("âœ… Aciliyet Seviyesi baÅŸarÄ±yla hesaplandÄ± ve yeni veri seti kaydedildi!")
import pandas as pd

# TemizlenmiÅŸ veri setini yÃ¼kle
df = pd.read_csv("aciliyetli_veri_seti.csv")

# SayÄ±sal olmayan (object tÃ¼rÃ¼nde) sÃ¼tunlarÄ± listele
object_columns = df.select_dtypes(include=["object"]).columns

print("ğŸ“Œ SayÄ±sal Olmayan SÃ¼tunlar:")
print(object_columns)

import pandas as pd

# TemizlenmiÅŸ veri setini yÃ¼kle
df = pd.read_csv("aciliyetli_veri_seti.csv")

# One-Hot Encoding uygulayarak sayÄ±sal hale getirme
df = pd.get_dummies(df, columns=["HastanÄ±n_Medikal_GeÃ§miÅŸi", "AÄŸrÄ±_Konumu"])

# Yeni veri setini kaydet
df.to_csv("son_hali_veri_seti.csv", index=False)

print("âœ… Metinsel sÃ¼tunlar sayÄ±sallaÅŸtÄ±rÄ±ldÄ± ve yeni veri seti kaydedildi!")

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import pickle

# Yeni temizlenmiÅŸ veri setini yÃ¼kle
df = pd.read_csv("son_hali_veri_seti.csv")

# BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) ve hedef deÄŸiÅŸken (y) ayÄ±rma
X = df.drop(columns=["Aciliyet_Seviyesi"])  # Model iÃ§in kullanÄ±lacak deÄŸiÅŸkenler
y = df["Aciliyet_Seviyesi"]  # Modelin tahmin edeceÄŸi hedef deÄŸiÅŸken

# Veriyi eÄŸitim (%80) ve test (%20) olarak bÃ¶lme
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Modeli oluÅŸtur ve eÄŸit
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Test verisiyle tahmin yap ve doÄŸruluk oranÄ±nÄ± hesapla
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

# Modeli kaydet
with open("trained_model.pkl", "wb") as file:
    pickle.dump(model, file)

# SonuÃ§larÄ± ekrana yazdÄ±r
print(f"âœ… Model baÅŸarÄ±yla eÄŸitildi! DoÄŸruluk oranÄ±: {accuracy:.4f}")
print("ğŸ¯ Model 'trained_model.pkl' olarak kaydedildi.")

import pandas as pd
import pickle

# Modeli yÃ¼kle
with open("trained_model.pkl", "rb") as file:
    model = pickle.load(file)

# Veri setini tekrar yÃ¼kle
df = pd.read_csv("son_hali_veri_seti.csv")

# BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) ve hedef deÄŸiÅŸken (y)
X = df.drop(columns=["Aciliyet_Seviyesi"])
y = df["Aciliyet_Seviyesi"]

# Ä°lk 10 hastayÄ± test edelim
X_sample = X.iloc[:10]
y_sample = y.iloc[:10]

# Model ile tahmin yap
y_pred_sample = model.predict(X_sample)

# SonuÃ§larÄ± ekrana yazdÄ±r
print("âœ… Modelin Ä°lk 10 Hasta iÃ§in Tahmin SonuÃ§larÄ±:\n")
for i in range(10):
    print(f"Hasta {i+1}: GerÃ§ek Aciliyet={y_sample.iloc[i]} | Model Tahmini={y_pred_sample[i]}")

import pandas as pd

# Veri setini yÃ¼kle
df = pd.read_csv("son_hali_veri_seti.csv")

# Aciliyet seviyelerinin daÄŸÄ±lÄ±mÄ±nÄ± inceleyelim
print("ğŸ“Œ Aciliyet Seviyesi DaÄŸÄ±lÄ±mÄ±:")
print(df["Aciliyet_Seviyesi"].value_counts())

import pandas as pd
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split

# Veri setini yÃ¼kle
df = pd.read_csv("son_hali_veri_seti.csv")

# BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) ve hedef deÄŸiÅŸken (y)
X = df.drop(columns=["Aciliyet_Seviyesi"])
y = df["Aciliyet_Seviyesi"]

# SMOTE ile veri dengeleme
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

# Yeni denge saÄŸlanmÄ±ÅŸ veri setini kaydet
df_resampled = pd.DataFrame(X_resampled, columns=X.columns)
df_resampled["Aciliyet_Seviyesi"] = y_resampled

df_resampled.to_csv("dengelenmis_veri_seti.csv", index=False)

print("âœ… Veri dengeleme tamamlandÄ± ve yeni veri seti kaydedildi!")

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import pickle

# Yeni dengelenmiÅŸ veri setini yÃ¼kle
df = pd.read_csv("dengelenmis_veri_seti.csv")

# BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) ve hedef deÄŸiÅŸken (y) ayÄ±rma
X = df.drop(columns=["Aciliyet_Seviyesi"])  # Model iÃ§in kullanÄ±lacak deÄŸiÅŸkenler
y = df["Aciliyet_Seviyesi"]  # Modelin tahmin edeceÄŸi hedef deÄŸiÅŸken

# Veriyi eÄŸitim (%80) ve test (%20) olarak bÃ¶lme
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Modeli oluÅŸtur ve eÄŸit
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Test verisiyle tahmin yap ve doÄŸruluk oranÄ±nÄ± hesapla
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

# Modeli kaydet
with open("trained_model.pkl", "wb") as file:
    pickle.dump(model, file)

# SonuÃ§larÄ± ekrana yazdÄ±r
print(f"âœ… Model baÅŸarÄ±yla eÄŸitildi! DoÄŸruluk oranÄ±: {accuracy:.4f}")
print("ğŸ¯ Model 'trained_model.pkl' olarak kaydedildi.")

import pandas as pd
import pickle

# Modeli yÃ¼kle
with open("trained_model.pkl", "rb") as file:
    model = pickle.load(file)

# Yeni dengelenmiÅŸ veri setini yÃ¼kle
df = pd.read_csv("dengelenmis_veri_seti.csv")

# BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) ve hedef deÄŸiÅŸken (y)
X = df.drop(columns=["Aciliyet_Seviyesi"])
y = df["Aciliyet_Seviyesi"]

# Ä°lk 10 hastayÄ± test edelim
X_sample = X.iloc[:10]
y_sample = y.iloc[:10]

# Model ile tahmin yap
y_pred_sample = model.predict(X_sample)

# SonuÃ§larÄ± ekrana yazdÄ±r
print("âœ… Modelin Ä°lk 10 Hasta iÃ§in Tahmin SonuÃ§larÄ±:\n")
for i in range(10):
    print(f"Hasta {i+1}: GerÃ§ek Aciliyet={y_sample.iloc[i]} | Model Tahmini={y_pred_sample[i]}")
import pandas as pd

# DengelenmiÅŸ veri setini yÃ¼kle
df = pd.read_csv("dengelenmis_veri_seti.csv")

# Aciliyet seviyelerinin daÄŸÄ±lÄ±mÄ±nÄ± inceleyelim
print("ğŸ“Œ DengelenmiÅŸ Veri Setindeki Aciliyet Seviyesi DaÄŸÄ±lÄ±mÄ±:")
print(df["Aciliyet_Seviyesi"].value_counts())
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import pickle

# Yeni dengelenmiÅŸ veri setini yÃ¼kle
df = pd.read_csv("dengelenmis_veri_seti.csv")

# BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) ve hedef deÄŸiÅŸken (y) ayÄ±rma
X = df.drop(columns=["Aciliyet_Seviyesi"])  # Model iÃ§in kullanÄ±lacak deÄŸiÅŸkenler
y = df["Aciliyet_Seviyesi"]  # Modelin tahmin edeceÄŸi hedef deÄŸiÅŸken

# Veriyi eÄŸitim (%80) ve test (%20) olarak bÃ¶lme
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Modeli oluÅŸtur ve eÄŸit (Daha az kompleks hale getiriyoruz)
model = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42)
model.fit(X_train, y_train)

# Test verisiyle tahmin yap ve doÄŸruluk oranÄ±nÄ± hesapla
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

# Modeli kaydet
with open("trained_model.pkl", "wb") as file:
    pickle.dump(model, file)

# SonuÃ§larÄ± ekrana yazdÄ±r
print(f"âœ… Yeni model eÄŸitildi! DoÄŸruluk oranÄ±: {accuracy:.4f}")
print("ğŸ¯ Model 'trained_model.pkl' olarak kaydedildi.")

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import pickle

# Yeni dengelenmiÅŸ veri setini yÃ¼kle
df = pd.read_csv("dengelenmis_veri_seti.csv")

# BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) ve hedef deÄŸiÅŸken (y) ayÄ±rma
X = df.drop(columns=["Aciliyet_Seviyesi"])  # Model iÃ§in kullanÄ±lacak deÄŸiÅŸkenler
y = df["Aciliyet_Seviyesi"]  # Modelin tahmin edeceÄŸi hedef deÄŸiÅŸken

# Veriyi eÄŸitim (%80) ve test (%20) olarak bÃ¶lme
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Modeli oluÅŸtur ve eÄŸit
model = LogisticRegression(max_iter=200, random_state=42)
model.fit(X_train, y_train)

# Test verisiyle tahmin yap ve doÄŸruluk oranÄ±nÄ± hesapla
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

# Modeli kaydet
with open("trained_model.pkl", "wb") as file:
    pickle.dump(model, file)

# SonuÃ§larÄ± ekrana yazdÄ±r
print(f"âœ… Yeni model (Logistic Regression) eÄŸitildi! DoÄŸruluk oranÄ±: {accuracy:.4f}")
print("ğŸ¯ Model 'trained_model.pkl' olarak kaydedildi.")

import pandas as pd
import pickle

# Modeli yÃ¼kle
with open("trained_model.pkl", "rb") as file:
    model = pickle.load(file)

# Yeni dengelenmiÅŸ veri setini yÃ¼kle
df = pd.read_csv("dengelenmis_veri_seti.csv")

# BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) ve hedef deÄŸiÅŸken (y)
X = df.drop(columns=["Aciliyet_Seviyesi"])
y = df["Aciliyet_Seviyesi"]

# Ä°lk 10 hastayÄ± test edelim
X_sample = X.iloc[:10]
y_sample = y.iloc[:10]

# Model ile tahmin yap
y_pred_sample = model.predict(X_sample)

# SonuÃ§larÄ± ekrana yazdÄ±r
print("âœ… Modelin Ä°lk 10 Hasta iÃ§in Tahmin SonuÃ§larÄ±:\n")
for i in range(10):
    print(f"Hasta {i+1}: GerÃ§ek Aciliyet={y_sample.iloc[i]} | Model Tahmini={y_pred_sample[i]}")

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score
import pickle

# Yeni dengelenmiÅŸ veri setini yÃ¼kle
df = pd.read_csv("dengelenmis_veri_seti.csv")

# BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) ve hedef deÄŸiÅŸken (y) ayÄ±rma
X = df.drop(columns=["Aciliyet_Seviyesi"])  # Model iÃ§in kullanÄ±lacak deÄŸiÅŸkenler
y = df["Aciliyet_Seviyesi"]  # Modelin tahmin edeceÄŸi hedef deÄŸiÅŸken

# Veriyi eÄŸitim (%80) ve test (%20) olarak bÃ¶lme
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# XGBoost modelini oluÅŸtur ve eÄŸit
model = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42)
model.fit(X_train, y_train)

# Test verisiyle tahmin yap ve doÄŸruluk oranÄ±nÄ± hesapla
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

# Modeli kaydet
with open("trained_model.pkl", "wb") as file:
    pickle.dump(model, file)

# SonuÃ§larÄ± ekrana yazdÄ±r
print(f"âœ… Yeni model (XGBoost) eÄŸitildi! DoÄŸruluk oranÄ±: {accuracy:.4f}")
print("ğŸ¯ Model 'trained_model.pkl' olarak kaydedildi.")

import pandas as pd
import pickle

# Modeli yÃ¼kle
with open("trained_model.pkl", "rb") as file:
    model = pickle.load(file)

# Yeni dengelenmiÅŸ veri setini yÃ¼kle
df = pd.read_csv("dengelenmis_veri_seti.csv")

# BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) ve hedef deÄŸiÅŸken (y)
X = df.drop(columns=["Aciliyet_Seviyesi"])
y = df["Aciliyet_Seviyesi"]

# Ä°lk 10 hastayÄ± test edelim
X_sample = X.iloc[:10]
y_sample = y.iloc[:10]

# Model ile tahmin yap
y_pred_sample = model.predict(X_sample)

# SonuÃ§larÄ± ekrana yazdÄ±r
print("âœ… Modelin Ä°lk 10 Hasta iÃ§in Tahmin SonuÃ§larÄ±:\n")
for i in range(10):
    print(f"Hasta {i+1}: GerÃ§ek Aciliyet={y_sample.iloc[i]} | Model Tahmini={y_pred_sample[i]}")
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score

# Yeni dengelenmiÅŸ veri setini yÃ¼kle
df = pd.read_csv("dengelenmis_veri_seti.csv")

# BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) ve hedef deÄŸiÅŸken (y) ayÄ±rma
X = df.drop(columns=["Aciliyet_Seviyesi"])  # Model iÃ§in kullanÄ±lacak deÄŸiÅŸkenler
y = df["Aciliyet_Seviyesi"]  # Modelin tahmin edeceÄŸi hedef deÄŸiÅŸken

# Veriyi eÄŸitim (%80) ve test (%20) olarak bÃ¶lme
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# XGBoost modelini oluÅŸtur ve eÄŸit
model = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42)
model.fit(X_train, y_train)

# Test verisiyle tahmin yap ve doÄŸruluk oranÄ±nÄ± hesapla
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

# Modeli JSON formatÄ±nda kaydet (app.py iÃ§in uygun format)
model.save_model("trained_model.json")

# SonuÃ§larÄ± ekrana yazdÄ±r
print(f"âœ… Yeni model (XGBoost) eÄŸitildi ve JSON formatÄ±nda kaydedildi! DoÄŸruluk oranÄ±: {accuracy:.4f}")
print("ğŸ¯ Model 'trained_model.json' olarak kaydedildi ve `app.py` dosyasÄ±nda kullanÄ±labilir.")
import pandas as pd
import numpy as np
import xgboost as xgb

# Modeli JSON formatÄ±nda yÃ¼kle
model = xgb.Booster()
model.load_model("trained_model.json")

# Yeni dengelenmiÅŸ veri setini yÃ¼kle
df = pd.read_csv("dengelenmis_veri_seti.csv")

# BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) ve hedef deÄŸiÅŸken (y)
X = df.drop(columns=["Aciliyet_Seviyesi"])
y = df["Aciliyet_Seviyesi"]

# Ä°lk 20 hastayÄ± test edelim
X_sample = X.iloc[:20]
y_sample = y.iloc[:20]

# XGBoost iÃ§in DMatrix formatÄ±na Ã§evir
dmatrix = xgb.DMatrix(X_sample)

# Model ile tahmin yap
y_pred_sample = model.predict(dmatrix)
y_pred_sample = np.round(y_pred_sample).astype(int)  # Tahminleri tam sayÄ±ya yuvarla ve tamsayÄ±ya Ã§evir

# SonuÃ§larÄ± ekrana yazdÄ±r
print("âœ… Modelin Ä°lk 20 Hasta iÃ§in Tahmin SonuÃ§larÄ±:\n")
for i in range(20):
    print(f"Hasta {i+1}: GerÃ§ek Aciliyet={y_sample.iloc[i]} | Model Tahmini={y_pred_sample[i]}")

import pandas as pd
import numpy as np
import xgboost as xgb

# Modeli JSON formatÄ±nda yÃ¼kle
model = xgb.Booster()
model.load_model("trained_model.json")

# Yeni dengelenmiÅŸ veri setini yÃ¼kle
df = pd.read_csv("dengelenmis_veri_seti.csv")

# BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) ve hedef deÄŸiÅŸken (y)
X = df.drop(columns=["Aciliyet_Seviyesi"])
y = df["Aciliyet_Seviyesi"]

# Ä°lk 20 hastayÄ± test edelim
X_sample = X.iloc[:20]
y_sample = y.iloc[:20]

# XGBoost iÃ§in DMatrix formatÄ±na Ã§evir
dmatrix = xgb.DMatrix(X_sample)

# Model ile tahmin yap
y_pred_sample = model.predict(dmatrix)
y_pred_sample = np.argmax(y_pred_sample, axis=1)  # En yÃ¼ksek olasÄ±lÄ±ÄŸÄ± alan sÄ±nÄ±fÄ± seÃ§

# SonuÃ§larÄ± ekrana yazdÄ±r
print("âœ… Modelin Ä°lk 20 Hasta iÃ§in Tahmin SonuÃ§larÄ±:\n")
for i in range(20):
    print(f"Hasta {i+1}: GerÃ§ek Aciliyet={y_sample.iloc[i]} | Model Tahmini={y_pred_sample[i]}")
import pandas as pd

# Yeni dengelenmiÅŸ veri setini yÃ¼kle
df = pd.read_csv("dengelenmis_veri_seti.csv")

# Aciliyet seviyesi daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶rÃ¼ntÃ¼le
print("ğŸ“Œ Aciliyet Seviyesi DaÄŸÄ±lÄ±mÄ±:\n")
print(df["Aciliyet_Seviyesi"].value_counts())
import pandas as pd
from sklearn.preprocessing import MinMaxScaler

# Yeni dengelenmiÅŸ veri setini yÃ¼kle
df = pd.read_csv("dengelenmis_veri_seti.csv")

# BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) ve hedef deÄŸiÅŸken (y)
X = df.drop(columns=["Aciliyet_Seviyesi"])
y = df["Aciliyet_Seviyesi"]

# Min-Max Ã¶lÃ§ekleyici ile veriyi normalleÅŸtirme
scaler = MinMaxScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)

# Yeni Ã¶lÃ§eklenmiÅŸ veri setini kaydedelim
df_scaled = pd.concat([X_scaled, y], axis=1)
df_scaled.to_csv("dengelenmis_veri_seti_normalize.csv", index=False)

print("âœ… Veri baÅŸarÄ±yla normalleÅŸtirildi ve kaydedildi: 'dengelenmis_veri_seti_normalize.csv'")

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score

# NormalleÅŸtirilmiÅŸ veri setini yÃ¼kle
df = pd.read_csv("dengelenmis_veri_seti_normalize.csv")

# BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) ve hedef deÄŸiÅŸken (y)
X = df.drop(columns=["Aciliyet_Seviyesi"])
y = df["Aciliyet_Seviyesi"]

# Veriyi eÄŸitim (%80) ve test (%20) olarak bÃ¶lme
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# XGBoost modelini oluÅŸtur ve eÄŸit
model = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42)
model.fit(X_train, y_train)

# Test verisiyle tahmin yap ve doÄŸruluk oranÄ±nÄ± hesapla
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

# Modeli JSON formatÄ±nda kaydet (app.py iÃ§in uygun format)
model.save_model("trained_model.json")

# SonuÃ§larÄ± ekrana yazdÄ±r
print(f"âœ… Yeni model (XGBoost) eÄŸitildi ve JSON formatÄ±nda kaydedildi! DoÄŸruluk oranÄ±: {accuracy:.4f}")
print("ğŸ¯ Model 'trained_model.json' olarak kaydedildi ve `app.py` dosyasÄ±nda kullanÄ±labilir.")

import pandas as pd
import numpy as np
import xgboost as xgb

# Modeli JSON formatÄ±nda yÃ¼kle
model = xgb.Booster()
model.load_model("trained_model.json")

# Yeni normalleÅŸtirilmiÅŸ veri setini yÃ¼kle
df = pd.read_csv("dengelenmis_veri_seti_normalize.csv")

# BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) ve hedef deÄŸiÅŸken (y)
X = df.drop(columns=["Aciliyet_Seviyesi"])
y = df["Aciliyet_Seviyesi"]

# Ä°lk 20 hastayÄ± test edelim
X_sample = X.iloc[:20]
y_sample = y.iloc[:20]

# XGBoost iÃ§in DMatrix formatÄ±na Ã§evir
dmatrix = xgb.DMatrix(X_sample)

# Model ile tahmin yap
y_pred_sample = model.predict(dmatrix)
y_pred_sample = np.argmax(y_pred_sample, axis=1)  # En yÃ¼ksek olasÄ±lÄ±ÄŸÄ± alan sÄ±nÄ±fÄ± seÃ§

# SonuÃ§larÄ± ekrana yazdÄ±r
print("âœ… Modelin Ä°lk 20 Hasta iÃ§in Tahmin SonuÃ§larÄ±:\n")
for i in range(20):
    print(f"Hasta {i+1}: GerÃ§ek Aciliyet={y_sample.iloc[i]} | Model Tahmini={y_pred_sample[i]}")
import pandas as pd
from sklearn.model_selection import train_test_split

# NormalleÅŸtirilmiÅŸ veri setini yÃ¼kle
df = pd.read_csv("dengelenmis_veri_seti_normalize.csv")

# BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) ve hedef deÄŸiÅŸken (y)
X = df.drop(columns=["Aciliyet_Seviyesi"])
y = df["Aciliyet_Seviyesi"]

# Veriyi eÄŸitim (%80) ve test (%20) olarak bÃ¶lme
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# EÄŸitim ve test verisinde sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±
print("ğŸ“Œ EÄŸitim Verisindeki SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±:")
print(y_train.value_counts())

print("\nğŸ“Œ Test Verisindeki SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±:")
print(y_test.value_counts())

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# NormalleÅŸtirilmiÅŸ veri setini yÃ¼kle
df = pd.read_csv("dengelenmis_veri_seti_normalize.csv")

# BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) ve hedef deÄŸiÅŸken (y)
X = df.drop(columns=["Aciliyet_Seviyesi"])
y = df["Aciliyet_Seviyesi"]

# Veriyi eÄŸitim (%80) ve test (%20) olarak bÃ¶lme
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Random Forest modelini oluÅŸtur ve eÄŸit
model = RandomForestClassifier(n_estimators=100, max_depth=6, random_state=42)
model.fit(X_train, y_train)

# Test verisiyle tahmin yap ve doÄŸruluk oranÄ±nÄ± hesapla
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

# Modeli Pickle formatÄ±nda kaydet (app.py iÃ§in uygun format)
import pickle
with open("trained_model.pkl", "wb") as file:
    pickle.dump(model, file)

# SonuÃ§larÄ± ekrana yazdÄ±r
print(f"âœ… Yeni model (RandomForest) eÄŸitildi ve Pickle formatÄ±nda kaydedildi! DoÄŸruluk oranÄ±: {accuracy:.4f}")
print("ğŸ¯ Model 'trained_model.pkl' olarak kaydedildi ve `app.py` dosyasÄ±nda kullanÄ±labilir.")
import pandas as pd
import pickle

# Modeli yÃ¼kle
with open("trained_model.pkl", "rb") as file:
    model = pickle.load(file)

# NormalleÅŸtirilmiÅŸ veri setini yÃ¼kle
df = pd.read_csv("dengelenmis_veri_seti_normalize.csv")

# BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) ve hedef deÄŸiÅŸken (y)
X = df.drop(columns=["Aciliyet_Seviyesi"])
y = df["Aciliyet_Seviyesi"]

# Ä°lk 20 hastayÄ± test edelim
X_sample = X.iloc[:20]
y_sample = y.iloc[:20]

# Model ile tahmin yap
y_pred_sample = model.predict(X_sample)

# SonuÃ§larÄ± ekrana yazdÄ±r
print("âœ… Modelin Ä°lk 20 Hasta iÃ§in Tahmin SonuÃ§larÄ±:\n")
for i in range(20):
    print(f"Hasta {i+1}: GerÃ§ek Aciliyet={y_sample.iloc[i]} | Model Tahmini={y_pred_sample[i]}")
import pandas as pd
import pickle

# Modeli yÃ¼kle
with open("trained_model.pkl", "rb") as file:
    model = pickle.load(file)

# Ã–zellik Ã¶nemlerini al
feature_importance = pd.DataFrame({"Ã–zellik": X.columns, "Ã–nem": model.feature_importances_})
feature_importance = feature_importance.sort_values(by="Ã–nem", ascending=False)

# Ä°lk 20 Ã¶zelliÄŸi gÃ¶ster
print("ğŸ“Œ Modelin En Ã–nemli 20 DeÄŸiÅŸkeni:\n")
print(feature_importance.head(20))
import pandas as pd

# NormalleÅŸtirilmiÅŸ veri setini yÃ¼kle
df = pd.read_csv("dengelenmis_veri_seti_normalize.csv")

# Mevcut sÃ¼tun isimlerini gÃ¶ster
print("ğŸ“Œ Veri Setindeki Mevcut SÃ¼tunlar:\n")
print(df.columns.tolist())
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# NormalleÅŸtirilmiÅŸ veri setini yÃ¼kle
df = pd.read_csv("dengelenmis_veri_seti_normalize.csv")

# AÅŸÄ±rÄ± baskÄ±n deÄŸiÅŸkenleri Ã§Ä±karalÄ±m (GerÃ§ek sÃ¼tun isimlerini kullanÄ±yoruz!)
drop_features = ["Kan_Åekeri", "AÄŸrÄ±_Konumu_KarÄ±n", "Uzuv_Kopmasi",
                 "Beyin_Kanamasi", "Kalp_Krizi", "Ic_Kanama"]
X = df.drop(columns=["Aciliyet_Seviyesi"] + drop_features)
y = df["Aciliyet_Seviyesi"]

# Veriyi eÄŸitim (%80) ve test (%20) olarak bÃ¶lme
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# GÃ¼ncellenmiÅŸ RandomForest modeli oluÅŸtur ve eÄŸit
model = RandomForestClassifier(n_estimators=50, max_depth=3, random_state=42)
model.fit(X_train, y_train)

# Test verisiyle tahmin yap ve doÄŸruluk oranÄ±nÄ± hesapla
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

# Modeli Pickle formatÄ±nda kaydet (app.py iÃ§in uygun format)
import pickle
with open("trained_model.pkl", "wb") as file:
    pickle.dump(model, file)

# SonuÃ§larÄ± ekrana yazdÄ±r
print(f"âœ… Yeni model (RandomForest) eÄŸitildi ve Pickle formatÄ±nda kaydedildi! DoÄŸruluk oranÄ±: {accuracy:.4f}")
print("ğŸ¯ Model 'trained_model.pkl' olarak kaydedildi ve `app.py` dosyasÄ±nda kullanÄ±labilir.")
import pandas as pd

# NormalleÅŸtirilmiÅŸ veri setini yÃ¼kle
df = pd.read_csv("dengelenmis_veri_seti_normalize.csv")

# Aciliyet Seviyesi daÄŸÄ±lÄ±mÄ±nÄ± incele
print("ğŸ“Œ Veri Setindeki Aciliyet Seviyesi DaÄŸÄ±lÄ±mÄ±:\n")
print(df["Aciliyet_Seviyesi"].value_counts())
import pandas as pd
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import pickle

# NormalleÅŸtirilmiÅŸ veri setini yÃ¼kle
df = pd.read_csv("dengelenmis_veri_seti_normalize.csv")

# BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) ve hedef deÄŸiÅŸken (y)
X = df.drop(columns=["Aciliyet_Seviyesi"])
y = df["Aciliyet_Seviyesi"]

# Veriyi eÄŸitim (%80) ve test (%20) olarak bÃ¶lme
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# LightGBM modelini oluÅŸtur
model = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, random_state=42)

# Modeli eÄŸit
model.fit(X_train, y_train)

# Test verisiyle tahmin yap ve doÄŸruluk oranÄ±nÄ± hesapla
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

# Modeli Pickle formatÄ±nda kaydet (app.py iÃ§in uygun format)
with open("trained_model.pkl", "wb") as file:
    pickle.dump(model, file)

# SonuÃ§larÄ± ekrana yazdÄ±r
print(f"âœ… Yeni model (LightGBM) eÄŸitildi ve Pickle formatÄ±nda kaydedildi! DoÄŸruluk oranÄ±: {accuracy:.4f}")
print("ğŸ¯ Model 'trained_model.pkl' olarak kaydedildi ve `app.py` dosyasÄ±nda kullanÄ±labilir.")
import pandas as pd
import pickle

# Modeli yÃ¼kle
with open("trained_model.pkl", "rb") as file:
    model = pickle.load(file)

# NormalleÅŸtirilmiÅŸ veri setini yÃ¼kle
df = pd.read_csv("dengelenmis_veri_seti_normalize.csv")

# BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) ve hedef deÄŸiÅŸken (y)
X = df.drop(columns=["Aciliyet_Seviyesi"])
y = df["Aciliyet_Seviyesi"]

# Ä°lk 20 hastayÄ± test edelim
X_sample = X.iloc[:20]
y_sample = y.iloc[:20]

# Model ile tahmin yap
y_pred_sample = model.predict(X_sample)

# SonuÃ§larÄ± ekrana yazdÄ±r
print("âœ… Modelin Ä°lk 20 Hasta iÃ§in Tahmin SonuÃ§larÄ±:\n")
for i in range(20):
    print(f"Hasta {i+1}: GerÃ§ek Aciliyet={y_sample.iloc[i]} | Model Tahmini={y_pred_sample[i]}")
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectFromModel

# Veri setini yÃ¼kle
df = pd.read_csv("dengelenmis_veri_seti_normalize.csv")

# BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) ve hedef deÄŸiÅŸken (y)
X = df.drop(columns=["Aciliyet_Seviyesi"])
y = df["Aciliyet_Seviyesi"]

# Ã–nce RandomForest ile en Ã¶nemli deÄŸiÅŸkenleri belirleyelim
selector_model = RandomForestClassifier(n_estimators=100, random_state=42)
selector_model.fit(X, y)

# Ã–nemli deÄŸiÅŸkenleri seÃ§
selector = SelectFromModel(selector_model, threshold="median", prefit=True)
X_selected = selector.transform(X)

# SeÃ§ilen deÄŸiÅŸken isimlerini al
selected_features = X.columns[selector.get_support()]
print("\nğŸ“Œ SeÃ§ilen En Ã–nemli DeÄŸiÅŸkenler:\n", selected_features)

# Yeni veri setini oluÅŸtur
df_selected = pd.DataFrame(X_selected, columns=selected_features)
df_selected["Aciliyet_Seviyesi"] = y

# Yeni veri setini kaydet
df_selected.to_csv("optimized_data.csv", index=False)

print("\nâœ… Veri baÅŸarÄ±yla optimize edildi ve yeni veri seti kaydedildi: 'optimized_data.csv'")
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Optimize edilmiÅŸ veri setini yÃ¼kle
df = pd.read_csv("optimized_data.csv")

# BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) ve hedef deÄŸiÅŸken (y)
X = df.drop(columns=["Aciliyet_Seviyesi"])
y = df["Aciliyet_Seviyesi"]

# Veriyi eÄŸitim ve test setine ayÄ±r
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Yeni model oluÅŸtur ve eÄŸit
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Modelin doÄŸruluk oranÄ±nÄ± hesapla
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

# Modeli kaydet
import joblib
joblib.dump(model, "trained_model.pkl")

print(f"\nâœ… Yeni model eÄŸitildi! DoÄŸruluk oranÄ±: {accuracy:.4f}")
print("ğŸ¯ Model 'trained_model.pkl' olarak kaydedildi ve `app.py` dosyasÄ±nda kullanÄ±labilir.")

import pandas as pd
import joblib

# Modeli yÃ¼kle
model = joblib.load("trained_model.pkl")

# Test verisini yÃ¼kle
df = pd.read_csv("optimized_data.csv")

# Ä°lk 20 hastayÄ± test edelim
X_test = df.drop(columns=["Aciliyet_Seviyesi"]).head(20)
y_real = df["Aciliyet_Seviyesi"].head(20)

# Model tahmini yap
y_pred = model.predict(X_test)

# Tahmin sonuÃ§larÄ±nÄ± ekrana yazdÄ±r
print("\nâœ… Modelin Ä°lk 20 Hasta iÃ§in Tahmin SonuÃ§larÄ±:\n")
for i in range(20):
    print(f"Hasta {i+1}: GerÃ§ek Aciliyet={y_real.iloc[i]} | Model Tahmini={y_pred[i]}")

print("\nâœ… Model tahminleri baÅŸarÄ±yla tamamlandÄ±!")
print(f"X_test boyutu: {X_test.shape}")
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) ve baÄŸÄ±mlÄ± deÄŸiÅŸken (y)
X = df.drop(columns=["Aciliyet_Seviyesi"])  # Hedef deÄŸiÅŸkeni Ã§Ä±kardÄ±k
y = df["Aciliyet_Seviyesi"]  # Hedef deÄŸiÅŸken

# Veriyi %80 eÄŸitim - %20 test olarak bÃ¶lelim
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Modeli yeniden eÄŸitelim
model.fit(X_train, y_train)

# Yeni test tahminlerini alalÄ±m
y_pred_test = model.predict(X_test)

# BoyutlarÄ± kontrol edelim
print(f"y_test boyutu: {len(y_test)}")
print(f"y_pred_test boyutu: {len(y_pred_test)}")

# Modelin sÄ±nÄ±flandÄ±rma performansÄ±nÄ± gÃ¶sterelim
print(classification_report(y_test, y_pred_test))
import pickle

# Modeli kaydet
with open("trained_model.pkl", "wb") as f:
    pickle.dump(model, f)
import pickle

# Modeli yÃ¼kle
with open("trained_model.pkl", "rb") as f:
    model = pickle.load(f)

# Modelin tipini kontrol et
print(type(model))  # EÄŸer <class 'numpy.ndarray'> olarak Ã§Ä±karsa, yanlÄ±ÅŸ yÃ¼klenmiÅŸ demektir.
import pickle

# 1ï¸âƒ£ Modeli yÃ¼kle
with open("trained_model.pkl", "rb") as f:
    model = pickle.load(f)

# 2ï¸âƒ£ Modelin tipini ekrana yazdÄ±r
print(f"âœ… Model baÅŸarÄ±yla yÃ¼klendi: {type(model)}")

# 3ï¸âƒ£ Modelin tahmin yapÄ±p yapmadÄ±ÄŸÄ±nÄ± kontrol et
if hasattr(model, "predict"):
    print("âœ… Model tahmin yapabiliyor!")
else:
    print("âš ï¸ Model tahmin yapamÄ±yor, yanlÄ±ÅŸ kaydedilmiÅŸ olabilir.")
import numpy as np

# 1ï¸âƒ£ Ã–rnek bir hasta verisi oluÅŸturalÄ±m (Rastgele veri, gerÃ§ek verilere uygun olmalÄ±)
sample_patient = np.array([[0.55, 1, 0.8, 0.6, 0.75, 0, 1, 0, 0, 1,
                            1, 0, 0, 1, 0.9, 0.7, 0.3, 0, 1, 0,
                            0.6, 0.4, 0.7, 0.8, 1, 0.5, 0.3, 0, 1, 1,
                            0, 0, 1, 0, 1, 0, 0, 0.5, 1, 0.8,
                            0, 1, 0]])

# 2ï¸âƒ£ Modelin tahmin yapmasÄ±nÄ± saÄŸla
prediction = model.predict(sample_patient)

# 3ï¸âƒ£ Tahmin sonucunu ekrana yazdÄ±r
print(f"ğŸš‘ Modelin Tahmini: {prediction[0]}")
import pandas as pd

# 1ï¸âƒ£ Test iÃ§in bir Ã¶rnek hasta verisi oluÅŸturalÄ±m (sÃ¼tun isimleriyle birlikte)
columns = ['BMI', 'NabÄ±z', 'Tansiyon_Sistolik', 'Tansiyon_Diastolik', 'Oksijen_DoygunluÄŸu',
           'Kalp_Hastaligi', 'Kanser', 'Kolesterol_Sorunu', 'Kalp_Krizi', 'Ic_Kanama',
           'Kesik', 'Beyin_Kanamasi', 'Uzuv_Kopmasi', 'Omurilik_Zedelenmesi', 'AÄŸrÄ±_Seviyesi',
           'Stres_Seviyesi', 'AteÅŸ', 'Epilepsi', 'BÃ¶brek_YetmezliÄŸi', 'Åiddetli_BaÅŸ_AÄŸrÄ±sÄ±',
           'Laboratuvar_SonuÃ§larÄ±', 'Kan_Åekeri', 'Kalp_HÄ±zÄ±_DeÄŸiÅŸkenliÄŸi', 'VÃ¼cut_SÄ±caklÄ±ÄŸÄ±_DeÄŸiÅŸkenliÄŸi',
           'Son_24_Saatte_Yemek_Yedi', 'Hasta_KaÃ§_Saat_Ã–nce_YaralandÄ±', 'HastanÄ±n_Ã–nceki_Hastane_Ziyaretleri',
           'Acil_Servise_GeldiÄŸi_Saat', 'BilinÃ§_Durumu_BilinÃ§siz', 'BilinÃ§_Durumu_Normal',
           'BilinÃ§_Durumu_Sersem', 'YanÄ±k_1. Derece', 'YanÄ±k_2. Derece', 'YanÄ±k_3. Derece',
           'Olay_TÃ¼rÃ¼_Sanayi KazasÄ±', 'GÃ¶z_BebeÄŸi_Tepkisi_Tepkisiz', 'NÃ¶rolojik_Belirtiler_UyuÅŸukluk',
           'HastanÄ±n_Medikal_GeÃ§miÅŸi_BÃ¶brek', 'HastanÄ±n_Medikal_GeÃ§miÅŸi_Normal', 'HastanÄ±n_Medikal_GeÃ§miÅŸi_NÃ¶rolojik',
           'AÄŸrÄ±_Konumu_KarÄ±n', 'AÄŸrÄ±_Konumu_Kol', 'AÄŸrÄ±_Konumu_SÄ±rt']

# 2ï¸âƒ£ Veriyi pandas DataFrame formatÄ±na Ã§evirelim
sample_patient_df = pd.DataFrame([sample_patient[0]], columns=columns)

# 3ï¸âƒ£ Modelin tahmin yapmasÄ±nÄ± saÄŸlayalÄ±m
prediction = model.predict(sample_patient_df)

# 4ï¸âƒ£ Tahmin sonucunu ekrana yazdÄ±ralÄ±m
print(f"ğŸš‘ Modelin Tahmini (DÃ¼zeltildi): {prediction[0]}")
import pickle
import numpy as np

# ğŸ“Œ Modeli yÃ¼kle
with open("trained_model.pkl", "rb") as file:
    model = pickle.load(file)

print(f"âœ… Model baÅŸarÄ±yla yÃ¼klendi: {type(model)}")

# ğŸ“Œ Ã–rnek bir hasta verisi (SÄ±ralama: SeÃ§tiÄŸin Ã¶zelliklere gÃ¶re olmalÄ±!)
sample_patient = np.array([[35, 1, 24.5, 80, 120, 80, 98, 1, 0, 0, 1, 0, 0, 0, 1, 0, 8, 7, 38.2, 0, 120, 5.5, 36.5, 1, 2, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0]])

# ğŸ“Œ Tahmin yap
prediction = model.predict(sample_patient)

print(f"ğŸš‘ Modelin Tahmini: {prediction[0]}")

import pickle
import pandas as pd
import numpy as np

# ğŸ“Œ Modeli yÃ¼kleyelim
with open("trained_model.pkl", "rb") as file:
    model = pickle.load(file)

# ğŸ“Œ Modelin beklediÄŸi Ã¶zellikleri al
expected_features = model.feature_names_in_

# ğŸ“Œ Yeni hasta verisi (Ã¶rnek)
sample_patient = {
    "BMI": 22.5,
    "NabÄ±z": 80,
    "Tansiyon_Sistolik": 120,
    "Tansiyon_Diastolik": 80,
    "Oksijen_DoygunluÄŸu": 98,
    "Kalp_Hastaligi": 0,
    "Kanser": 0,
    "Kolesterol_Sorunu": 1,
    "Kalp_Krizi": 0,
    "Ic_Kanama": 0,
    "Kesik": 1,
    "Beyin_Kanamasi": 0,
    "Uzuv_Kopmasi": 0,
    "Omurilik_Zedelenmesi": 0,
    "AÄŸrÄ±_Seviyesi": 5,
    "Stres_Seviyesi": 3,
    "AteÅŸ": 37.2,
    "Epilepsi": 0,
    "BÃ¶brek_YetmezliÄŸi": 0,
    "Åiddetli_BaÅŸ_AÄŸrÄ±sÄ±": 1,
    "Laboratuvar_SonuÃ§larÄ±": 1,
    "Kan_Åekeri": 90,
    "Kalp_HÄ±zÄ±_DeÄŸiÅŸkenliÄŸi": 75,
    "VÃ¼cut_SÄ±caklÄ±ÄŸÄ±_DeÄŸiÅŸkenliÄŸi": 0.5,
    "Son_24_Saatte_Yemek_Yedi": 1,
    "Hasta_KaÃ§_Saat_Ã–nce_YaralandÄ±": 2,
    "HastanÄ±n_Ã–nceki_Hastane_Ziyaretleri": 0,
    "Acil_Servise_GeldiÄŸi_Saat": 12,
    "BilinÃ§_Durumu_BilinÃ§siz": 0,
    "BilinÃ§_Durumu_Normal": 1,
    "BilinÃ§_Durumu_Sersem": 0,
    "YanÄ±k_1. Derece": 0,
    "YanÄ±k_2. Derece": 0,
    "YanÄ±k_3. Derece": 0,
    "Olay_TÃ¼rÃ¼_Sanayi KazasÄ±": 0,
    "GÃ¶z_BebeÄŸi_Tepkisi_Tepkisiz": 0,
    "NÃ¶rolojik_Belirtiler_UyuÅŸukluk": 0,
    "HastanÄ±n_Medikal_GeÃ§miÅŸi_BÃ¶brek": 0,
    "HastanÄ±n_Medikal_GeÃ§miÅŸi_Normal": 1,
    "HastanÄ±n_Medikal_GeÃ§miÅŸi_NÃ¶rolojik": 0,
    "AÄŸrÄ±_Konumu_KarÄ±n": 1,
    "AÄŸrÄ±_Konumu_Kol": 0,
    "AÄŸrÄ±_Konumu_SÄ±rt": 0
}

# ğŸ“Œ Hasta verisini DataFrame formatÄ±na Ã§evirelim
patient_df = pd.DataFrame([sample_patient])

# ğŸ“Œ **Eksik veya fazla sÃ¼tunlarÄ± dÃ¼zeltelim**
for feature in expected_features:
    if feature not in patient_df.columns:
        patient_df[feature] = 0  # Eksik sÃ¼tunlarÄ± 0 ile doldur

# ğŸ“Œ Fazla sÃ¼tunlarÄ± temizleyelim
patient_df = patient_df[expected_features]

# ğŸ“Œ Model ile tahmin yapalÄ±m
prediction = model.predict(patient_df)[0]

print(f"ğŸš‘ Modelin Tahmini (DÃ¼zeltilmiÅŸ): {prediction}")

import joblib

# Modelin deÄŸiÅŸkeni 'model' olmalÄ±dÄ±r. EÄŸer farklÄ±ysa uygun olanÄ± yaz.
joblib.dump(model, "trained_model_final.pkl")

print("âœ… Model baÅŸarÄ±yla kaydedildi: trained_model_final.pkl")
import joblib

# Modeli yÃ¼kle
model = joblib.load("trained_model_final.pkl")

print("âœ… Model baÅŸarÄ±yla yÃ¼klendi:", type(model))
from sklearn.metrics import classification_report, accuracy_score

# Daha Ã¶nce ayrÄ±lmÄ±ÅŸ test verilerini kullan
y_pred_test = model.predict(X_test)

# Modelin doÄŸruluÄŸunu Ã¶lÃ§elim
accuracy = accuracy_score(y_test, y_pred_test)
print(f"ğŸ¯ Modelin Test DoÄŸruluk OranÄ±: {accuracy:.4f}")

# SÄ±nÄ±flandÄ±rma raporunu yazdÄ±ralÄ±m
print("ğŸ“Œ SÄ±nÄ±flandÄ±rma Raporu:\n", classification_report(y_test, y_pred_test))

import numpy as np
import pandas as pd

# Modelin eÄŸitildiÄŸi sÃ¼tun isimlerini al
feature_names = X_test.columns  # EÄŸer X_test yoksa, eÄŸitildiÄŸi veri kÃ¼mesindeki sÃ¼tunlarÄ± kullan

# Rastgele bir hasta oluÅŸtur
sample_patient = np.random.rand(1, len(feature_names))  # Rastgele deÄŸerler oluÅŸtur
sample_patient_df = pd.DataFrame(sample_patient, columns=feature_names)  # Veriyi DataFrame'e Ã§evir

# Model tahminini yap
prediction = model.predict(sample_patient_df)[0]
print(f"ğŸš‘ Modelin Tahmini (Rastgele Hasta): {prediction}")

import numpy as np

# Her sÄ±nÄ±f iÃ§in 3 Ã¶rnek hasta alalÄ±m
for urgency_level in [0, 1, 2]:
    print(f"\nğŸ©º Aciliyet Seviyesi: {urgency_level} iÃ§in test ediliyor...")

    # O sÄ±nÄ±fa ait rastgele 3 hasta seÃ§
    sample_patients = X_test[y_test == urgency_level].sample(3, random_state=42)

    # Model tahminleri yap
    predictions = model.predict(sample_patients)

    # SonuÃ§larÄ± gÃ¶ster
    for i, pred in enumerate(predictions, 1):
        print(f"ğŸ”¹ Hasta {i}: GerÃ§ek={urgency_level} | Model Tahmini={pred}")
import joblib

# Modeli kaydet
joblib.dump(model, "trained_model_final.pkl")

# Ã–zellik isimlerini kaydet (modelin doÄŸru Ã§alÄ±ÅŸmasÄ± iÃ§in gerekli!)
feature_names = list(X_test.columns)
joblib.dump(feature_names, "model_features.pkl")

print("âœ… Model ve Ã¶zellikler baÅŸarÄ±yla kaydedildi!")

import pickle

with open("trained_model.pkl", "rb") as file:
    model = pickle.load(file)

print(model.feature_names_in_)  # Modelin beklediÄŸi sÃ¼tunlarÄ± listeler

print("âœ… Modelin beklediÄŸi sÃ¼tunlar:", model.feature_names_in_)

import joblib

# Modeli kaydet
joblib.dump(model, "trained_model_final.pkl")

# Modelin Ã¶zellik isimlerini kaydet
feature_names = list(X_train.columns)  # EÄŸitimde kullanÄ±lan sÃ¼tunlar
joblib.dump(feature_names, "model_features.pkl")

print("âœ… Model ve Ã¶zellikler baÅŸarÄ±yla kaydedildi!")



import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
# Mevcut veri setini DataFrame'e Ã§eviriyoruz
df = pd.DataFrame(data)

# 1. "Evet" - "HayÄ±r" sÃ¼tunlarÄ±nÄ± 0-1 olarak Ã§eviriyoruz
evet_hayir_kolonlari = [
    "Kalp_Hastaligi", "Kanser", "Tansiyon_Problemi", "Panik_Atak", "Son_Ameliyat",
    "Kirik", "Cikik", "Kalp_Krizi", "Ic_Kanama", "Kesik", "Yaralanma", "Beyin_Kanamasi",
    "Uzuv_Kopmasi", "Sikisma", "Omurilik_Zedelenmesi", "BulantÄ±", "Kusma", "BayÄ±lma",
    "Epilepsi", "KOAH", "BÃ¶brek_YetmezliÄŸi", "Zehirlenme", "BoÄŸulma", "Nefes_DarlÄ±ÄŸÄ±",
    "Åok_Belirtileri", "Ä°shal", "GÃ¶ÄŸÃ¼s_AÄŸrÄ±sÄ±", "Susuzluk_Belirtileri", "Son_24_Saatte_Yemek_Yedi", "Cilt_KuruluÄŸu"
]
for kolon in evet_hayir_kolonlari:
    df[kolon] = df[kolon].map({"Evet": 1, "HayÄ±r": 0})

# ğŸ”¥ Bunu ekliyoruz
df = df.replace({"Evet": 1, "HayÄ±r": 0})

# 2. Kategorik deÄŸiÅŸkenleri one-hot encoding ile dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yoruz
one_hot_kolonlar = [
    "Cinsiyet", "BilinÃ§_Durumu", "YanÄ±k", "HastanÄ±n_Medikal_GeÃ§miÅŸi",
    "GÃ¶z_BebeÄŸi_Tepkisi", "NÃ¶rolojik_Belirtiler", "Olay_TÃ¼rÃ¼", "AÄŸrÄ±_Konumu"
]
df = pd.get_dummies(df, columns=one_hot_kolonlar)

# 3. Hedef deÄŸiÅŸkeni (etiket)
df["Aciliyet_Seviyesi"] = np.random.choice([0, 1, 2], size=len(df))  # 0=Normal, 1=Acil, 2=Kritik

# 4. Ã–zellikler ve hedef ayrÄ±mÄ±
X = df.drop("Aciliyet_Seviyesi", axis=1)
y = df["Aciliyet_Seviyesi"]

# 5. EÄŸitim ve test seti
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 6. Model eÄŸitimi
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

print("âœ… Model yeniden baÅŸarÄ±yla eÄŸitildi!")
import joblib

# EÄŸittiÄŸimiz yeni modeli kaydediyoruz
joblib.dump(model, "model_yeni.pkl")  # Ä°SÄ°MÄ° FARKLI YAPTIK âœ…

# Modelin beklediÄŸi sÃ¼tunlarÄ± da kaydediyoruz
joblib.dump(list(X.columns), "model_yeni_sutunlar.pkl")  # Ä°SÄ°MÄ° FARKLI YAPTIK âœ…

print("âœ… Yeni model ve Ã¶zellikler baÅŸarÄ±yla kaydedildi! (model_yeni.pkl)")
import joblib

# ğŸ”¹ Yeni eÄŸittiÄŸimiz modeli kaydediyoruz
joblib.dump(model, "trained_model_yeni.pkl")
joblib.dump(X_train.columns.tolist(), "model_features_yeni.pkl")

print("âœ… Yeni model ve Ã¶zellikler baÅŸarÄ±yla 'trained_model_yeni.pkl' ve 'model_features_yeni.pkl' olarak kaydedildi!")
